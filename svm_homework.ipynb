{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "75ac20f6",
      "metadata": {
        "id": "75ac20f6"
      },
      "source": [
        "# Description\n",
        "\n",
        "This notebook is part of an assignment made during the subject of Computational Intelligence, 7th semester at Federal University of ParÃ¡.\n",
        "\n",
        "Professor: Aldebaro Klautau\n",
        "\n",
        "Authors:\n",
        "\n",
        "    - Bruno Martins\n",
        "    - Claudio Matheus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6a6684",
      "metadata": {
        "id": "be6a6684"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d5c652c",
      "metadata": {
        "id": "2d5c652c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d916902",
      "metadata": {
        "id": "3d916902"
      },
      "source": [
        "## Assure the libraries have the same version as used throughout the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7064d66",
      "metadata": {
        "id": "f7064d66"
      },
      "outputs": [],
      "source": [
        "assert mpl.__version__ == '3.5.3'\n",
        "assert pd.__version__ == '1.3.5'\n",
        "assert np.__version__ == '1.19.5'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc20ce3",
      "metadata": {
        "id": "9cc20ce3"
      },
      "source": [
        "## Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d72028",
      "metadata": {
        "id": "77d72028"
      },
      "outputs": [],
      "source": [
        "DATASET_ROOT_PATH = './datasets/svm_homework/'\n",
        "\n",
        "VALIDATION_PATH = os.path.join(DATASET_ROOT_PATH, 'dataset_validation.txt')\n",
        "TRAIN_PATH = os.path.join(DATASET_ROOT_PATH, 'dataset_train.txt')\n",
        "TEST_PATH = os.path.join(DATASET_ROOT_PATH, 'dataset_test.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d64ccf27",
      "metadata": {
        "id": "d64ccf27"
      },
      "outputs": [],
      "source": [
        "validation = pd.read_csv(VALIDATION_PATH, header=None)\n",
        "train = pd.read_csv(TRAIN_PATH, header=None)\n",
        "test = pd.read_csv(TEST_PATH, header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef105ee8",
      "metadata": {
        "id": "ef105ee8"
      },
      "source": [
        "## Separate features from labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fba6d5",
      "metadata": {
        "id": "f7fba6d5"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, X_val = train.iloc[:, :-1], test.iloc[:, :-1], validation.iloc[:, :-1]\n",
        "y_train, y_test, y_val = train.iloc[:, -1], test.iloc[:, -1], validation.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b781d8d9",
      "metadata": {
        "id": "b781d8d9"
      },
      "source": [
        "## First Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb999486",
      "metadata": {
        "id": "eb999486"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC, LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75826c71",
      "metadata": {
        "id": "75826c71"
      },
      "outputs": [],
      "source": [
        "def train_svm_classifiers(X: list, y: list) -> list:\n",
        "    \"\"\"\n",
        "        Trains 4 different svm classifiers\n",
        "    \"\"\"\n",
        "    models = []\n",
        "    model_1 = LinearSVC()\n",
        "    model_1.fit(X,y)\n",
        "    models.append(model_1)\n",
        "    model_2 = SVC()\n",
        "    model_2.fit(X,y)\n",
        "    models.append(model_2)\n",
        "    model_3 = SVC()\n",
        "    model_3.fit(X,y)\n",
        "    models.append(model_3)\n",
        "    model_4 = SVC()\n",
        "    model_4.fit(X,y)\n",
        "    models.append(model_4)\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8953cba0",
      "metadata": {
        "id": "8953cba0",
        "outputId": "391626ed-281e-4676-f445-0f7bf0418f70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bruno/anaconda3/envs/federated_learning/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "models = train_svm_classifiers(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee4d352",
      "metadata": {
        "id": "8ee4d352"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
        "ax[0,0].plot()\n",
        "ax[0,0].set_xlabel()\n",
        "ax[0,1].plot()\n",
        "ax[0,1].set_xlabel()\n",
        "ax[1,0].plot()\n",
        "ax[1,0].set_xlabel()\n",
        "ax[1,1].plot()\n",
        "ax[1,1].set_xlabel()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d17d02",
      "metadata": {
        "id": "31d17d02"
      },
      "source": [
        "## Second Question"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In sckit-learn there is a hyperparameter that crontols the quantities of support vectors of a model. This parameter is called C. Therefore, it works in this way: if C is substantially a high value, then, the numbers of support vectors will be smaller. Alternatively, if C is considerably a low value, then, the quantities of support vectors will be huge.\n",
        "\n",
        "![SVM_C_values](https://raw.githubusercontent.com/Euronym/computational_intelligence_2022/main/images/C_values_SVM.png)\n",
        "\n",
        "In the words, the width of the way between the convex-hull and the hyperplan of the model will be minor for the high value of C, and larger for the low value of C. Provoking, respectively, a decrease of support vectors and an increase of them."
      ],
      "metadata": {
        "id": "3wKDTyaY9CbZ"
      },
      "id": "3wKDTyaY9CbZ"
    },
    {
      "cell_type": "markdown",
      "id": "829994b0",
      "metadata": {
        "id": "829994b0"
      },
      "source": [
        "## Third Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d849e6d3",
      "metadata": {
        "id": "d849e6d3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8f6c027e",
      "metadata": {
        "id": "8f6c027e"
      },
      "source": [
        "## Fourth Question"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "svm.n_support_= [1 2]\n",
        "\n",
        "svm.support_vectors_= [[ 1. 4.] [-2.  3.] [-2. -5.]]\n",
        "\n",
        "svm.dual_coef_= [[-0.5 -0.3 0.8]]\n",
        "\n",
        "svc.intercept_= [-2]\n",
        "\n",
        "### Item (A):\n",
        "Considering these attributes above, there is below the decision model:\n",
        "\n",
        "$f(z) = -0.5 \\times <z, [1, 4]>  -0.3 \\times <z, [-2, 3]> + 0.8 \\times <z, [1, 4]> -2$\n",
        "\n",
        "\n",
        "### Item (B):\n",
        "For a SVM as a perceptron it's quite similar to the previous models, nevertheless, there is important difference, as we'll see in the next:\n",
        "\n",
        "First of all, it's known that weight $w$ of perceptron defintion ($f(z)= <z, w> + b$) is defined by:\n",
        "\n",
        "$w = \\displaystyle\\sum_{i = 0}^{N-1}\\lambda_{n} x_i$\n",
        "\n",
        "where $\\lambda$ in sckit-learn API is identified by a variable called *dual_coef_*.\n",
        "\n",
        "Therefore, using the general definition of SVM and the associative property of dot product, there is the development of definition of SVM as a perceptron:\n",
        "\n",
        "$f(z) = \\displaystyle\\sum_{i = 0}^{N-1}\\lambda_{n}K(z, x_n) + b$\n",
        "\n",
        "- Assuming that is a linear kernel:\n",
        "\n",
        "$f(z) = \\displaystyle\\sum_{i = 0}^{N-1}\\lambda_{n}<z, x_n> + b$\n",
        "\n",
        "- And finally, using associative property of dot product:\n",
        "\n",
        "$f(z) = \\displaystyle\\sum_{i = 0}^{N-1}<z, \\lambda_{n}x_n> + b$\n",
        "\n",
        "$f(z) = \\displaystyle\\sum_{i = 0}^{N-1}<z, w> + b$\n",
        "\n",
        "Now, applying this definition for the SVM in this problem, we have the final result:\n",
        "\n",
        "$f(z) = <z, [-0.5, 2]> + <z, [0.6, 0.9]> + <z, [-1.6, -4]> -2$\n",
        "\n",
        "### item (C):\n",
        "First of all considering $I(f(z))$ \"indicative\" function, where is defined like this:\n",
        "\n",
        "$I(f(z))=\\begin{cases}\n",
        "    1, & f(z) > 0\\\\\n",
        "    0, & \\text{otherwise}.\n",
        "  \\end{cases}$\n",
        "\n",
        "So, evaluate $f(z)$ for $z = [0, 0]$, we have this:\n",
        "\n",
        "$f([0, 0]) = -0.5 \\times <[0, 0], [1, 4]>  -0.3 \\times <[0, 0], [-2, 3]> + 0.8 \\times <[0, 0], [1, 4]> -2$\n",
        "\n",
        "It's quite clear that dot product between a vector at origin and any other vector result in value 0. Therefore, the result of these three dot product is 0. So:\n",
        "\n",
        "$f([0, 0]) = 0 - 2$\n",
        "\n",
        "$f([0, 0]) = -2$\n",
        "\n",
        "Using this result in \"indicative\" function, we have this:\n",
        "\n",
        "$I(f([0, 0])) = 0$"
      ],
      "metadata": {
        "id": "2tbULSBx-LZS"
      },
      "id": "2tbULSBx-LZS"
    },
    {
      "cell_type": "markdown",
      "id": "71ecd30f",
      "metadata": {
        "id": "71ecd30f"
      },
      "source": [
        "## Fifth Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22087518",
      "metadata": {
        "id": "22087518"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e81d7c8e",
      "metadata": {
        "id": "e81d7c8e"
      },
      "source": [
        "## Sixth Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e55083",
      "metadata": {
        "id": "33e55083"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "31ff003c",
      "metadata": {
        "id": "31ff003c"
      },
      "source": [
        "## Seventh Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6835a002",
      "metadata": {
        "id": "6835a002"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "federated_learning",
      "language": "python",
      "name": "federated_learning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}