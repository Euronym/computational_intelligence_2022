{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-means"
      ],
      "metadata": {
        "id": "NuW603_sJSF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "d3AZn8HBlrxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Question\n",
        "\n",
        "Show two centroids given this dataset and the Voronoi tesselation"
      ],
      "metadata": {
        "id": "fNlxSG3uWQze"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6LPR5g1HTNN"
      },
      "outputs": [],
      "source": [
        "train_dataset = np.array(\n",
        "    [[ -3,  4],\n",
        "     [2 ,  0],\n",
        "     [4,  -4],\n",
        "     [4,  3],\n",
        "     [0,  2],\n",
        "     [2,  1],\n",
        "     [1,  -1],\n",
        "     [5,  3]])\n",
        "\n",
        "k = 2\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "y_pred = kmeans.fit_predict(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEBujI8WIvSj",
        "outputId": "4e535338-db33-44d4-d138-937b1d5f16e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.cluster_centers_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inY9TFnMI0vH",
        "outputId": "12158687-4bd1-4be8-d086-35caa6a6968a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.        ,  0.33333333],\n",
              "       [-1.5       ,  3.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Voronoi Tessellation"
      ],
      "metadata": {
        "id": "I_UvF3yaJMfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(X):\n",
        "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=8)\n",
        "\n",
        "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='r'):\n",
        "    if weights is not None:\n",
        "        centroids = centroids[weights > weights.max() / 10]\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "                marker='o', s=35, linewidths=8,\n",
        "                color=circle_color, zorder=10, alpha=0.9)\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "                marker='x', s=2, linewidths=12,\n",
        "                color=cross_color, zorder=11, alpha=1)\n",
        "\n",
        "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
        "                             show_xlabels=True, show_ylabels=True):\n",
        "    mins = X.min(axis=0) - 0.1\n",
        "    maxs = X.max(axis=0) + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
        "                         np.linspace(mins[1], maxs[1], resolution))\n",
        "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
        "                cmap=\"Pastel2\")\n",
        "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
        "                linewidths=1, colors='k')\n",
        "    plot_data(X)\n",
        "    if show_centroids:\n",
        "        plot_centroids(clusterer.cluster_centers_)\n",
        "\n",
        "    if show_xlabels:\n",
        "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
        "    else:\n",
        "        plt.tick_params(labelbottom=False)\n",
        "    if show_ylabels:\n",
        "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
        "    else:\n",
        "        plt.tick_params(labelleft=False)"
      ],
      "metadata": {
        "id": "Vb0yFkpkJXHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plot_decision_boundaries(kmeans, train_dataset)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "iPqXF_6UJaSS",
        "outputId": "905d7067-113f-49cf-fa06-29d08f46fe64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Question\n",
        "An alternative solution for large train dataset that can be allocated directly on RAM memory due restrictions of the problem or infrastructure"
      ],
      "metadata": {
        "id": "Gnid21OUSK6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT_PATH = './datasets/k_means_homework/'\n",
        "\n",
        "TRAIN_PATH = os.path.join(DATASET_ROOT_PATH, 'dataset_train.txt')\n",
        "TEST_PATH = os.path.join(DATASET_ROOT_PATH, 'dataset_test.txt')\n",
        "\n",
        "## Remove useless features\n",
        "X = np.loadtxt(TRAIN_PATH, delimiter=',')\n",
        "\n",
        "X_0 = np.delete(X, np.s_[3:], axis=0)\n",
        "X_1 = np.delete(X, np.s_[:3], axis=0) \n",
        "\n",
        "X_0 = np.delete(X_0, np.s_[2:], axis=1)\n",
        "X_1 = np.delete(X_1, np.s_[2:], axis=1)  \n",
        "\n",
        "print(f'X_0 = {X_0}')\n",
        "print()\n",
        "print(f'X_1 = {X_1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zo2irbMk1R3",
        "outputId": "151a5011-72ff-4014-a9cb-6f22130a9fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_0 = [[ 0.e+00 -4.e+00]\n",
            " [-1.e+03  2.e+00]\n",
            " [ 3.e+03  3.e+00]]\n",
            "\n",
            "X_1 = [[-5.e+03 -6.e+00]\n",
            " [-4.e+03 -5.e+00]\n",
            " [-2.e+03 -2.e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sum_0, sum_1 = 0, 0\n",
        "\n",
        "# mean for first centroid\n",
        "for i in range(len(X_0)):\n",
        "    sum_0 += X_0[i][0] \n",
        "    sum_1 += X_0[i][1] \n",
        "\n",
        "centroid_0 = [sum_0/len(X_0), sum_1/len(X_0)]\n",
        "\n",
        "sum_0, sum_1 = 0, 0\n",
        "\n",
        "# mean for sencond centroid\n",
        "for i in range(len(X_1)):\n",
        "    sum_0 += X_1[i][0] \n",
        "    sum_1 += X_1[i][1] \n",
        "\n",
        "centroid_1 = [sum_0/len(X_0), sum_1/len(X_0)]    \n",
        "\n",
        "# Inserting the previous label for each vector\n",
        "centroid_0.append(0)\n",
        "centroid_1.append(1)\n",
        "\n",
        "print(f'centroid_0: {centroid_0}')\n",
        "print(f'centroid_1: {centroid_1}')\n",
        "\n"
      ],
      "metadata": {
        "id": "cei2LP35SKs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95200b6-6081-4234-cf05-64782e6de93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "centroid_0: [666.6666666666666, 0.3333333333333333, 0]\n",
            "centroid_1: [-3666.6666666666665, -4.333333333333333, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifing the Test Dataset"
      ],
      "metadata": {
        "id": "wMGalJXCvzzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the dataset\n",
        "train_dataset = np.array([centroid_0, centroid_1])\n",
        "test_dataset = np.loadtxt(TEST_PATH, delimiter=',')\n",
        "\n",
        "# Split the dataset \n",
        "X_train, X_test = np.delete(train_dataset, np.s_[2:], axis=1), np.delete(test_dataset, np.s_[2:], axis=1)\n",
        "y_train, y_test = np.delete(train_dataset, np.s_[:-1], axis=1), np.delete(test_dataset, np.s_[:-1], axis=1)\n",
        "\n",
        "# Transform the array in column vectors\n",
        "y_train = np.ravel(y_train,order='C')\n",
        "y_test = np.ravel(y_test,order='C')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "model = scaler.fit(X_train)\n",
        "X_train_scaled = model.transform(X_train)\n",
        "X_test_scaled = model.transform(X_test)\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors = 1)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "result = clf.predict(X_test_scaled)\n",
        "\n",
        "print(f'Label: {y_test}')\n",
        "print(f'Predict: {result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RskviCq3vzQR",
        "outputId": "4e6fe5cb-93f0-4a04-8579-d6e8a85750b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: [0. 0. 1. 1.]\n",
            "Predict: [0. 0. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Third Question\n",
        "\n",
        "A little talk about K-means, K-means++ and K-medoids"
      ],
      "metadata": {
        "id": "NkMy16-Ce3qA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This algorithm was proposed by Stuart Lloyd in 1957. The first application was associated to vector quantization in signal processing, more precisely as PCM(pulse-code modulation) technique. \n",
        "\n",
        "Now, about K-medoids, it's an algorithm whose is very similar to k-means and k-means++ approach, once the purpose of k-medoids is clustering and, hence, labeling data of unlabel dataset. In this way, an approach to explain the operation of k-medoid model is understading, before, how these similar models works, because, k-medoid using them as sub-routine in its operation.\n",
        "\n",
        "Therefore, is can be possible explain these model breaks apart each algorithms in three methods: \n",
        "\n",
        "- Initialization\n",
        "- Assignment\n",
        "- Updation \n",
        "\n",
        "Thereby:\n",
        "\n",
        "### $k$-means Operation\n",
        "The K-means operation is known to using Lloyd algorithm to clustering some unlabel dataset. So, the first thing that Lloyd algorithm is define the $K$ centroid of the clusters. This definition is the major feature of this algorithm, that is, a **random initialization**. Hence, given a dataset with $n$ instances, the Lloyd algol will choice randomically $K$ instances to represent the firsts centroid of each cluster. \n",
        "\n",
        "Chosen the centroids, the algorithm will be labeling each instance based in the distance between this instance and each centroid cluster. That instance will receive the label of cluster that represents the less distance to itself. Naturally, the way of this distance will be evaluated depending of the problem.\n",
        "\n",
        "Lastly, as the K-means is a iterative model, it's necessary update the centroid to find the optimal soluation of the problem. Naturally, this optimal not necessarilly will be a global optimal, being able, therefore, just a local optimal.\n",
        "\n",
        "Hence, to choose the new centroid for next iteration, the mean between the instances of each cluster will be evaluated and this midpoint will be the new centroid of your cluster. And so on, the process will be repeated until reaching to an optimal solution, local or global.\n",
        "\n",
        "### $k$-means++ Operation\n",
        "K-means++ represents an improvent of Lloyd's Algorithm purpose by David Artur and Sergei Vassilvitskii in an paper called \"k-means: The Advantages of Careful Seeding\". in this related work, the authors discuss an enhance about the initialization process purpose to solve an old problem of k-means initialization, that is, the generation of _poor cluster_ due a bad choice of centroids in this process. By the way, in this context, poor cluster means a horrible clustering of your dataset, like a graphic comparative in the next:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Euronym/computational_intelligence_2022/main/images/poor_cluster.png\" width=\"300\" height=\"300\" />\n",
        "<img src=\"https://raw.githubusercontent.com/Euronym/computational_intelligence_2022/main/images/ideal_cluster.png\" width=\"300\" height=\"300\" />\n",
        "\n",
        "Hence, to solve this problem and avoid bad clustering, the authors purpose a sub-routine to choice the best centroid in the dataset and reach the ideal clustering. To this purpose the following algorithm is used:\n",
        "\n",
        "- Choose a instance randomically from the dataset for being your first centroid;\n",
        "- Compute a distance $D(x)$ for each $x$ point in the dataset to this centroid. Like always, this distance depend of your problem;\n",
        "- Choose the next centroid based in the beside probability: $\\dfrac{D(x')^2}{\\sum_{x \\in \\chi}D(x)^2}$\n",
        "- Repeat this process until reach in the $K$ cluster defined.\n",
        "\n",
        "In the matter of fact, this process garantuees that chosen centroids will be distant to each other, due fact the probability is proportional to a distance between a centroid and the next centroid cluster.\n",
        "\n",
        "Lastly, once done this initialization, the k-means++ model operate similarly to k-means. \n",
        "\n",
        "\n",
        "### $k$-medoid Operation\n",
        "Considering the explanation of above model, it's more simple to understading how operate the PAM(Partitioning Around Medoids) algorithm in K-medoid. So, it model use the same method of k-means++ to iniatialize your centroid. Furthermore, use the same of k-means to assign the label in the data of the problem. Hence, the diference be in the **update process**. \n",
        "\n",
        "Now, before explain how the updation process works in k-medoid, it's interesting discuss the reasons to this modification and, in this way, the major reason is the purpose to avoid the possible negative effects to the model of outliers and noisy data when we have using mean update approach \n",
        "\n",
        "Thus, the k-medoid using a cost function to decide which instance will be the new centroid of the cluster. Thereby, imagine the you have iniatilize your cluster with $K$ centroids, evaluate each distance between the instances and the centroids(sometimes called as dissimilarity value), so with these elements, for update these centroid, it's necessary yet evaluate, lastly, the value of cost function using the below formula: \n",
        "\n",
        "$C = \\sum_{i=1}^{k}\\sum_{x \\in \\chi} ||X - C_i||^2$\n",
        "\n",
        "And in possess with this cost C, can be proceed in this way:\n",
        "- Pick randomly another non-medoid $K$ centroids of your dataset, that is, the other ($C-1$) not yet chosen.\n",
        "- Evaluate the cost for these centroid using the formula above-mentioned\n",
        "- If this new cost is greater than previous one, so the centroid point will be updated, else, repeat until don't have anymome non-medoid points.   \n",
        "\n",
        "\n",
        "\n",
        "### The Summary of the Whole Models\n",
        "\n",
        "|Model |Iniatilization|Assignment  |Updation | \n",
        "|-----|:-----|:---:|:-----:|\n",
        "|K-means |Random Initialization  |The type of distance chosen  |Mean between instances of a cluster    |\n",
        "|K-means++|Using a probability|Same as K-means   |Same as K-means |\n",
        "|K-medoid|Same as K-means++|Same as K-means   |Using cost function |\n",
        "\n"
      ],
      "metadata": {
        "id": "CBqjz2kJhjtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fourth Question\n",
        "Some considerations about use of k-d tree in k-means model"
      ],
      "metadata": {
        "id": "AlLLirJ4e6MR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-d tree is an approach used by some models like k-NN and k-means to avoid to calculating a large number of distances between samples of dataset. In k-means, for example, this method avoid to evaluate a several number of distances between an instances of some dataset and a centroid. For this, k-d tree grouping the closest instances in regions, like rectangle. \n",
        "\n",
        "Naturally, there is few ways to split the dataset to create this regions. Usually, as we want a binary balanced tree, the median of instances of a region is used for this, however, using the median isn't the only way to achieve this this kind of tree, thus, there is another like use median in randomly sorted selected points of the dataset.\n",
        "\n",
        "![split_1](https://raw.githubusercontent.com/Euronym/computational_intelligence_2022/main/images/split_1_kd.png)\n",
        "![split_1](https://raw.githubusercontent.com/Euronym/computational_intelligence_2022/main/images/split_2_kd.png)\n",
        "\n",
        "![kd_tree_gif](https://raw.githubusercontent.com/Euronym/computational_intelligence_2022/main/images/KD-Tree.gif)\n",
        "<img src=\"https://raw.githubusercontent.com/Euronym/computational_intelligence_2022/main/images/kd_tree.png\" width=\"500\" height=\"300\" />\n",
        "\n",
        "Hence, the main idea about k-d tree implementations in k-means, is to leverage of these groups created, for then facilitate in the future evaluate. That is, imagine that you have to calculate the previous distances(distance between an instance and a centroid) to labeling the instances in the phase of assignment of k-means. Naturally if you have 2 centroid and $n$ instances, will be necessary does $2n$ distances evaluation to this centroid. Altough, when the k-d trees is in being used, this evaluation can be shortened, because, if you have a group of hyper-rectangle represented by a \"wall\" that split a closest instances, and you evaluate the distance between the centroid and the instance of this \"wall\", you will know the distance between the instances inside of the rectangle and the centroid can not be greater than the distance of the \"wall\". So, this distances of these inner instances won't need be calculate.\n",
        "\n"
      ],
      "metadata": {
        "id": "VJVEloFZHSzc"
      }
    }
  ]
}